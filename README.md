# Home-Credit-Default-Risk
De nombreuses personnes ont du mal à obtenir des prêts en raison de leurs historiques de crédit insuffisant ou inexistant. Et, malheureusement, cette population se dirige vers des prêteurs peu fiables.<br>
Home Credit est un groupe qui offre des crédits aux populations de 10 pays ayant qu’un petit historique bancaire ou même  pas. Le groupe offre des prêts à la consommation sans intérêt, en tirant profit du partenariat avec les fabricants et les détaillants (Il y’a des banques au Maroc qui offrent les même avantages en faisant des partenariats avec des groupes tel que la banque populaire avec  Electroplanet, Marjane…). Et cela peut perturber les services de crédit traditionnels et faire augmenter le nombre de client fidèle du groupe Home Credit. Et tout cela est grâce aux algorithmes d'auto-apprentissage avancés qui atténuent les risques et qui permettent de prendre des décisions de prêt rapides.<br>
Home Credit s'efforce d'élargir l'inclusion financière de la population non bancarisée en offrant une expérience d'emprunt positive et sûre. Le groupe peut se baser sur diverses données alternatives pour accorder un crédit, notamment des informations sur les opérateurs de télécommunication et les transactions, pour prévoir les capacités de remboursement de leurs clients.<br>
Bien que Home Credit utilise actuellement diverses méthodes statistiques et d’apprentissage automatique pour réaliser ces prévisions, Kaggle demande aux entreprises de les aider à exploiter pleinement le potentiel de leurs données. Cela garantira que les clients capables de remboursement ne seront pas refusés.<br>
L'objectif : est d'utiliser les données historiques des demandes de prêt pour prédire si un demandeur sera en mesure de rembourser un prêt. Il s'agit d'une tâche de classification supervisée standard:
- Supervisé: les étiquettes sont incluses dans les données   d'apprentissage et l'objectif est de former un modèle pour apprendre à prédire les étiquettes à partir des fonctionnalités.
- Classification: l'étiquette est une variable binaire, 0 (remboursera le prêt à temps), 1 (aura du mal à rembourser le prêt).

Dans ce kernel on a effectué une lecture des fichiers de données, une vérification des données manquantes, la suppression des attributs qui ont un taux de valeurs manquantes supérieure à 60% et le remplacement des autres avec la méthode Imputer (most frequent), la visualisation de la distribution de quelques variables y compris l’attribut cible où 282686 valeurs sont à 0 qui veut dire que ces contacteurs de prêts n’ont pas eu de problèmes pour embourser et 24825 sont à 1.<br>
On a ensuite procédé à la suppression des valeurs aberrantes : dans l’attribut DAYS_EMPLOYED y’avait plusieurs valeurs d’environ 1000 ans ce qui n’est pas normal, on a listé les attributs les plus corrélées avec l’attribut cible.<br>
On a ensuite traité les variables catégorielles parce qu’un modèle d'apprentissage automatique ne peut malheureusement pas traiter ces variables à l'exception de certains modèles tels que LightGBM. On doit alors trouver un moyen pour représenter ces variables sous forme de nombres avant de les transférer au modèle. Il y a deux manières principales qu’on a utilisées pour mener à bien ce processus:<br>
- Le label encoding où on assigne chaque catégorie unique dans une variable catégorielle avec un entier. (Aucune nouvelle colonne n'est créée).<br>
- Et le one-hot encoding où on crée une nouvelle colonne pour chaque catégorie unique dans une variable catégorielle. Chaque observation reçoit un 1 dans la colonne pour la catégorie correspondante et un 0 dans toutes les autres nouvelles colonnes.<br>

Ensuite on a appliqué des algorithmes suivant avant de faire du feature engineering: Decision Tree, KNN,K-Centroide, Stacking, Ridge, AdaBoo, BaggingClassifier, xgBoot, Gradient Boosting, Random Forest, MLP Classifier, Voting Classifier... et apres features engineering et bien sur en calculant à chaque fois l’accuracy, la précision, le rappel et F-mesure de chacun qui sont des critères permettant d'évaluer les modèles de classification. De façon non formelle, l’accuracy désigne la proportion des prédictions correctes effectuées par le modèle, la précision donne le pourcentage de réponses correctes, le rappel donne le pourcentage des réponses correctes qui sont données et finalement F-mesure pour combiner le rappel et la précision qui est considéré comme un bon indicateur de la relation entre eux.<br>
Pour savoir quel algorithme est le plus performant on affiche un factorplot.<br>
L’algorithme XGB avec un meilleur paramétrage est le plus performant. En outre, il a récemment dominé l’apprentissage automatique appliqué. XGBoost est une implémentation d'arbres de décision optimisés par gradient. Bien que, il a été conçu pour la vitesse et la performance. Fondamentalement, c'est un type de bibliothèque de logiciels. On l’a installé sur notre machine. Ensuite, on l’a importé dans le code pour l’utiliser.<br>
Xgboot donne toujours les meilleurs résultats avec ou sans feature selection.<br>
On a soumis nos résultats et on a obtenu un score de 0.66614<br>
 
